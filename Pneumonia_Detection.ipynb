{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning approach to Pneumonia Detection and Classification from Chest X-Ray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CueSKGS3K_QP"
   },
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rx-cxHxTKIxK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Conv2D , MaxPooling2D , Dropout , BatchNormalization , Flatten , MaxPool2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYeeqmT0M69o"
   },
   "source": [
    "### Build the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GFLrzWT7MOZp"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (256,256,3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units = 128 , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 1 , activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mEc46NFtOlk8",
    "outputId": "1c3dc2d0-7c87-4eb0-d53a-ddbe339bd1bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 256, 256, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256, 256, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 128, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 128, 128, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128, 128, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 64, 64, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 64, 64, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 32, 32, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32, 32, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 16, 16, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 16, 16, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 8, 8, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 16384)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               2097280   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,524,929\n",
      "Trainable params: 2,523,841\n",
      "Non-trainable params: 1,088\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KusxLSp1O1lO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import  Adam\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svvmFoVIO_y0"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U4UPwLpiL3_b"
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_dir = 'dataset//train'\n",
    "test_dir = 'dataset//test'\n",
    "val_dir = 'dataset//val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xI9NMc64K99Y",
    "outputId": "c635b3f9-3f0e-4576-b111-9cac03418be0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(256,256),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(256,256),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_generator = test_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(256,256),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDBe-QmhPJP0"
   },
   "source": [
    "### Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awlIBL_kUsPN",
    "outputId": "356c7f40-0968-4f76-c7e4-25bd8331a6ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "163/163 [==============================] - ETA: 0s - loss: 0.1298 - accuracy: 0.9534WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 624 batches). You may need to use the repeat() function when building your dataset.\n",
      "163/163 [==============================] - 64s 390ms/step - loss: 0.1298 - accuracy: 0.9534 - val_loss: 36.5900 - val_accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "163/163 [==============================] - 68s 417ms/step - loss: 0.1337 - accuracy: 0.9519\n",
      "Epoch 3/50\n",
      "163/163 [==============================] - 65s 398ms/step - loss: 0.1205 - accuracy: 0.9553\n",
      "Epoch 4/50\n",
      "163/163 [==============================] - 64s 394ms/step - loss: 0.1279 - accuracy: 0.9588\n",
      "Epoch 5/50\n",
      "163/163 [==============================] - 62s 380ms/step - loss: 0.1069 - accuracy: 0.9590\n",
      "Epoch 6/50\n",
      "163/163 [==============================] - 66s 401ms/step - loss: 0.1178 - accuracy: 0.9609\n",
      "Epoch 7/50\n",
      "163/163 [==============================] - 64s 392ms/step - loss: 0.1128 - accuracy: 0.9586\n",
      "Epoch 8/50\n",
      "163/163 [==============================] - 64s 395ms/step - loss: 0.1035 - accuracy: 0.9640\n",
      "Epoch 9/50\n",
      "163/163 [==============================] - 66s 406ms/step - loss: 0.1002 - accuracy: 0.9659\n",
      "Epoch 10/50\n",
      "163/163 [==============================] - 69s 425ms/step - loss: 0.0914 - accuracy: 0.9663\n",
      "Epoch 11/50\n",
      "163/163 [==============================] - 65s 400ms/step - loss: 0.0819 - accuracy: 0.9709\n",
      "Epoch 12/50\n",
      "163/163 [==============================] - 68s 414ms/step - loss: 0.0896 - accuracy: 0.9695\n",
      "Epoch 13/50\n",
      "163/163 [==============================] - 68s 419ms/step - loss: 0.0796 - accuracy: 0.9707\n",
      "Epoch 14/50\n",
      "163/163 [==============================] - 67s 413ms/step - loss: 0.0854 - accuracy: 0.9678\n",
      "Epoch 15/50\n",
      "163/163 [==============================] - 68s 419ms/step - loss: 0.0925 - accuracy: 0.9659\n",
      "Epoch 16/50\n",
      "163/163 [==============================] - 69s 421ms/step - loss: 0.0781 - accuracy: 0.9709\n",
      "Epoch 17/50\n",
      "163/163 [==============================] - 68s 414ms/step - loss: 0.0790 - accuracy: 0.9705\n",
      "Epoch 18/50\n",
      "163/163 [==============================] - 61s 374ms/step - loss: 0.0762 - accuracy: 0.9716\n",
      "Epoch 19/50\n",
      "163/163 [==============================] - 63s 383ms/step - loss: 0.0748 - accuracy: 0.9735\n",
      "Epoch 20/50\n",
      "163/163 [==============================] - 62s 382ms/step - loss: 0.0731 - accuracy: 0.9724\n",
      "Epoch 21/50\n",
      "163/163 [==============================] - 62s 381ms/step - loss: 0.0694 - accuracy: 0.9762\n",
      "Epoch 22/50\n",
      "163/163 [==============================] - 102s 627ms/step - loss: 0.0712 - accuracy: 0.9762\n",
      "Epoch 23/50\n",
      "163/163 [==============================] - 63s 387ms/step - loss: 0.0759 - accuracy: 0.9751\n",
      "Epoch 24/50\n",
      "163/163 [==============================] - 66s 406ms/step - loss: 0.0704 - accuracy: 0.9728\n",
      "Epoch 25/50\n",
      "163/163 [==============================] - 66s 404ms/step - loss: 0.0642 - accuracy: 0.9770\n",
      "Epoch 26/50\n",
      "163/163 [==============================] - 67s 409ms/step - loss: 0.0641 - accuracy: 0.9770\n",
      "Epoch 27/50\n",
      "163/163 [==============================] - 68s 418ms/step - loss: 0.0715 - accuracy: 0.9753\n",
      "Epoch 28/50\n",
      "163/163 [==============================] - 69s 421ms/step - loss: 0.0568 - accuracy: 0.9795\n",
      "Epoch 29/50\n",
      "163/163 [==============================] - 67s 412ms/step - loss: 0.0613 - accuracy: 0.9776\n",
      "Epoch 30/50\n",
      "163/163 [==============================] - 68s 417ms/step - loss: 0.0736 - accuracy: 0.9730\n",
      "Epoch 31/50\n",
      "163/163 [==============================] - 68s 414ms/step - loss: 0.0651 - accuracy: 0.9764\n",
      "Epoch 32/50\n",
      "163/163 [==============================] - 68s 419ms/step - loss: 0.0650 - accuracy: 0.9757\n",
      "Epoch 33/50\n",
      "163/163 [==============================] - 66s 403ms/step - loss: 0.0584 - accuracy: 0.9793\n",
      "Epoch 34/50\n",
      "163/163 [==============================] - 65s 400ms/step - loss: 0.0585 - accuracy: 0.9803\n",
      "Epoch 35/50\n",
      "163/163 [==============================] - 67s 407ms/step - loss: 0.0502 - accuracy: 0.9816\n",
      "Epoch 36/50\n",
      "163/163 [==============================] - 66s 404ms/step - loss: 0.0620 - accuracy: 0.9801\n",
      "Epoch 37/50\n",
      "163/163 [==============================] - 69s 423ms/step - loss: 0.0489 - accuracy: 0.9801\n",
      "Epoch 38/50\n",
      "163/163 [==============================] - 70s 431ms/step - loss: 0.0498 - accuracy: 0.9826\n",
      "Epoch 39/50\n",
      "163/163 [==============================] - 68s 415ms/step - loss: 0.0521 - accuracy: 0.9814\n",
      "Epoch 40/50\n",
      "163/163 [==============================] - 66s 402ms/step - loss: 0.0599 - accuracy: 0.9776\n",
      "Epoch 41/50\n",
      "163/163 [==============================] - 69s 426ms/step - loss: 0.0583 - accuracy: 0.9787\n",
      "Epoch 42/50\n",
      "163/163 [==============================] - 63s 384ms/step - loss: 0.0525 - accuracy: 0.9812\n",
      "Epoch 43/50\n",
      "163/163 [==============================] - 13860s 86s/step - loss: 0.0526 - accuracy: 0.9818\n",
      "Epoch 44/50\n",
      "163/163 [==============================] - 83s 507ms/step - loss: 0.0429 - accuracy: 0.9835\n",
      "Epoch 45/50\n",
      "163/163 [==============================] - 69s 423ms/step - loss: 0.0512 - accuracy: 0.9810\n",
      "Epoch 46/50\n",
      "163/163 [==============================] - 65s 401ms/step - loss: 0.0463 - accuracy: 0.9816\n",
      "Epoch 47/50\n",
      "163/163 [==============================] - 65s 399ms/step - loss: 0.0475 - accuracy: 0.9814\n",
      "Epoch 48/50\n",
      "163/163 [==============================] - 69s 419ms/step - loss: 0.0431 - accuracy: 0.9864\n",
      "Epoch 49/50\n",
      "163/163 [==============================] - 70s 427ms/step - loss: 0.0461 - accuracy: 0.9829\n",
      "Epoch 50/50\n",
      "163/163 [==============================] - 66s 402ms/step - loss: 0.0475 - accuracy: 0.9833\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                         steps_per_epoch = 163,\n",
    "                         epochs = 50,\n",
    "                         validation_data = val_generator,\n",
    "                         validation_steps = 624)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9MbWtLfaMHQF",
    "outputId": "86b474a3-e1a5-4b19-c771-d08ff898457b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20/624 [..............................] - ETA: 2:22 - loss: 1.8809 - accuracy: 0.7676WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 624 batches). You may need to use the repeat() function when building your dataset.\n",
      "624/624 [==============================] - 5s 7ms/step - loss: 1.8809 - accuracy: 0.7676\n",
      "163/163 [==============================] - 65s 397ms/step - loss: 2.2375 - accuracy: 0.7364\n",
      "The testing accuracy is : 76.76281929016113 %\n",
      "The training accuracy is : 73.63880276679993 %\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = model.evaluate(test_generator,steps=624)\n",
    "train_accuracy = model.evaluate(train_generator,steps=163)\n",
    "print('The testing accuracy is :',test_accuracy[1]*100, '%')\n",
    "print('The training accuracy is :',train_accuracy[1]*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models//Pneumonia_Model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Pneumonia_Prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
